FROM gettyimages/spark:2.1.0-hadoop-2.7

ENV DEBIAN_FRONTEND noninteractive

WORKDIR /srv/spark-stat-analyzer

RUN apt-get update && \
    apt-get -yq install \
        zip \
        netcat \
        && \
    rm -rf /var/lib/apt/lists/*

COPY requirements.txt requirements.txt
COPY requirements-test.txt requirements-test.txt

RUN set -xe && \
    buildDeps="libpq-dev python3-dev build-essential" && \
    apt-get update && \
    apt-get -yq install $buildDeps && \
    pip3 install -r requirements-test.txt && \
    apt-get purge -y --auto-remove -o APT::AutoRemove::RecommendsImportant=false -o APT::AutoRemove::SuggestsImportant=false $buildDeps && \
    rm -rf /var/lib/apt/lists/*

COPY . /srv/spark-stat-analyzer

RUN cp config.py.docker config.py && rm config.py.dist && rm config.py.docker
RUN zip -r spark-stat-analyzer.zip analyzers includes tests models.py
RUN cp /usr/spark-2.1.0/conf/log4j.properties.template /usr/spark-2.1.0/conf/log4j.properties
RUN sed -i 's/INFO, console/ERROR, console/g' /usr/spark-2.1.0/conf/log4j.properties

CMD ["./run_test.sh"]
